import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
import os
import time

# Ø±Ù†Ú¯â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø²ÛŒØ¨Ø§ØªØ± Ø´Ø¯Ù† Ù…Ø­ÛŒØ· (ANSI Escape Codes)
GREEN = '\033[92m'
RED = '\033[91m'
YELLOW = '\033[93m'
BLUE = '\033[94m'
RESET = '\033[0m'
BOLD = '\033[1m'

DOG_AVATAR = f"""
{BLUE}
      __
     /  \\
    / .. \\      {RESET}{BOLD}AlphaDog v2.0{RESET}{BLUE}
   (_\  /_)     {YELLOW}Status: Hunting...{RESET}{BLUE}
     /  \\
    /____\\      {RED}Ready to Bite!{RESET}
{BLUE}   /      \\
{RESET}
"""

TEST_BITES = [
    "<script>alert(1)</script>",
    "<img src=x onerror=alert(1)>"
]

class AlphaDog:
    def __init__(self, target):
        self.target = target
        self.domain = urlparse(target).netloc
        self.visited = set()
        self.findings_file = "ELIMINATED_THIEVES.txt"
        os.system('clear')
        print(DOG_AVATAR)
        print(f"{BLUE}[*] Ø´Ø±ÙˆØ¹ Ú¯Ø´Øªâ€ŒØ²Ù†ÛŒ Ø¯Ø± Ù‚Ù„Ù…Ø±Ùˆ: {target}{RESET}\n")

    def bark(self, msg, url, level="CRITICAL"):
        color = RED if level == "CRITICAL" else YELLOW
        output = f"\n{color}{BOLD}[!!!] {level} WOOF! {msg}{RESET}\n{BLUE}[TARGET]: {url}{RESET}\n"
        print(output)
        
        with open(self.findings_file, "a") as f:
            f.write(f"{time.ctime()} - {output}\n")
        
        # Ù„Ø±Ø²Ø´ Ùˆ Ø§Ø¹Ù„Ø§Ù† Ø§Ù†Ø¯Ø±ÙˆÛŒØ¯
        os.system("termux-vibrate -d 500")
        os.system(f"termux-notification -t 'Ø´Ú©Ø§Ø± Ø´Ø¯!' -c '{msg}'")

    def hunt(self, current_url):
        if current_url in self.visited or len(self.visited) > 100: # Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø¨Ø±Ø§ÛŒ ØªØ³Øª
            return
        self.visited.add(current_url)

        try:
            # Ù†Ù…Ø§ÛŒØ´ ÙˆØ¶Ø¹ÛŒØª Ø¨Ù‡ ØµÙˆØ±Øª Ø²Ù†Ø¯Ù‡ Ùˆ Ù…ØªØ­Ø±Ú©
            print(f"{GREEN} ğŸ¾ Ø¨Ùˆ Ú©Ø´ÛŒØ¯Ù†: {current_url[-40:]}{RESET}", end='\r')
            response = requests.get(current_url, timeout=5)
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # ØªØ³Øª XSS Ø§Ú¯Ø± ÙØ±Ù… Ù¾ÛŒØ¯Ø§ Ø´Ø¯
            if soup.find('form'):
                print(f"\n{YELLOW} ğŸ¦´ ÛŒÚ© Ø§Ø³ØªØ®ÙˆØ§Ù† (Form) Ù¾ÛŒØ¯Ø§ Ø´Ø¯! Ø¯Ø± Ø­Ø§Ù„ Ø¬ÙˆÛŒØ¯Ù†...{RESET}")
                self.test_xss(current_url)

            # Ø§Ø¯Ø§Ù…Ù‡ ØªØ¹Ù‚ÛŒØ¨
            for a in soup.find_all('a', href=True):
                full_url = urljoin(current_url, a['href'])
                if urlparse(full_url).netloc == self.domain:
                    self.hunt(full_url)

        except: pass

    def test_xss(self, url):
        for bite in TEST_BITES:
            try:
                test_url = f"{url}?q={bite}" 
                res = requests.get(test_url, timeout=5)
                if bite in res.text:
                    self.bark("Ø¯Ø²Ø¯ Ù¾ÛŒØ¯Ø§ Ø´Ø¯! Ø´Ú©Ø§Ù XSS!", test_url)
            except: pass

if __name__ == "__main__":
    target = "https://example.com" # Ø¢Ø¯Ø±Ø³ Ù‡Ø¯Ù
    dog = AlphaDog(target)
    try:
        dog.hunt(target)
    except KeyboardInterrupt:
        print(f"\n{BLUE}[!] Ø³Ú¯ Ø¨Ù‡ Ù„Ø§Ù†Ù‡ Ø¨Ø§Ø²Ú¯Ø´Øª.{RESET}")
